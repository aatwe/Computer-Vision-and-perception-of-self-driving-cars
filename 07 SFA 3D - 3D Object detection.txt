Database:
a) What given:
1) Kitty3d object detection datset (front cam)

2) lidar data

3) lidar data camera pov


b) What objective: 3d object detection
	What algo? SFA 3d
	what cool? only uses LIDAR data for 3d object detection
	//images not used

c) What special about this data?
	we will use realtime camera and lidar feed


d) How SFA3d works? (Super fast and accurate 3d object detection)
Data collected = LiDAR 3d data
			//top view = bird eye view

	Input SFA 3d: bird's eye view input Lidar
	
	What network does?  object detect + classify
	
	Output SFA 3d: 7 outputs
		heatmaps of classes in image
		what distance centre of object from car
		what angles other oobject facing in 
		dimensions of objects
		z coordinate of centre of object	


e) How SFA 3d works?

e.1) What 3 components in SFA 3d?
	e.1.1) keypoint FPN (Featured Pyarmind network)
			What is it? Feature extraction technique
				//Why extract feature? what are features? important data inside image (ex points,edges,designs,patterns,human faces)
				//Output from convolutional blocks = feature maps  	
				//process = feature extraction
		We will apply FPN technique on no. of neural networks
		What FPN will output? feature maps
		What network architecture we will apply on? ResNEt
		What use of feature maps? we can post process --> do tasks on it ex object detection
		 
		How FPN works?
		a) Get input image
		b) pass thru convolution blocks (downsample)
		     at threshold (pyramid tip) --> input image will become smaller
		d) pass again thru convolution blocks (upsample the image)
	     	     at base (pyramid base) --> input image will become larger
			//What is done in successive steps?
				convolution applied + get data from previous corresponding downsample steps

		e) Final Output: Output feature maps
		//This above network is scale invariant
		//if ball in image is small/large -> neural network will still predict
		//what are we detecting though? points --> scaling invariance not major role
	
		//What we learnt for keypoint pyramid network? extension to FPN

	
		e.1) What feature maps will look like? Gaussian shaped
			//what gaussian indicates? network is confident that point is present at given location in image

		


		f) Final step
			take reference = largest feature map
			upsample small feature maps (match to largest (reference))
			Calculate weighted average of all		//what weight to chose? confidence value network has in different feature maps
			Final output feature map
				//point with highest confidence value = point we wanted to detect
	
	e.1.2) different loss functions

		What output generated by SFA 3d network?

			1) Heat map of different classes	
				What is heat map? Data visualization technique	
					//mountain from top view
					//analyse height of ground
					//large height = dark red
					//low height = white


				What value represents in heat map? confidence network has in its predictions

			Ex if objective: detect 3 objects
			How to detect? 3 heat maps
			red = car at that location + network v confident
			
			//What insight we get? we learn what right classes are
			
			1.1) What use? if we found class imbalance in data (different confidence)
				Focal loss: less data for x class, more data for y class

			Pt = network confidence
			//helps network focus on learnings it is less confident about
			///focus less on what high confidence
			

			2) Distance from car + What direction other objects facing
			How we learn? identifying loss

			L1 loss = |y't - yt|  (predicton value - actual value)

			

			3) Dimensions of object to be detected	
			    Z Coordinate (height from ground)
			How we learn?
			Balanced L1 loss

			3.1) Why Balanced L1 loss
				Points in data = Outliers + Inliers

			If (training) --> datapoint generated loss < threshold (ex 1)
				--> Inliers			//weights not attracted
			If (training) --> datapoint generated loss > threshold (ex 1)
				--> Outliers			//Attract neural network weights attracted  //large loss


			3.2) How to deal with this loss value? Balanced L1 loss
			


	e.1.3) Learning rate scheduling 
			learning rate = parameter
			when training -> increase / decrease learning rate values : fine tune optimization process
				//What optimizing?
			
			e.1.3.1) What learning rate technique used? cosine annealing
			
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Algo in action


1) Configuration
	//Set up parameters and variables we will use for our network



2) Data processing functions
		Lidar data -> bird's eye view data

3) Utility functions:
	logging				//log training process
	learning rate scheudling		//use when training network
	visualization utility functions 	//visualize and generate final output	
	loss functions
	FPN ResNET

//training problem: time consuming + good network needed
	//use pre training weights provided by kaggle




Check final output:
camera view --> objects tracked and labelled
same in bird's eye view of lidar
	
	//red box = cars
	//blue box = pedestrian
	//cant detect tram	//not trained on data
	//blue line marks orientation  of objects